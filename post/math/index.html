<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> a post with math | You R. Name </title> <meta name="author" content="You R. Name"> <meta name="description" content="an example of a blog post with some math"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/Personal-Website-New/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/Personal-Website-New/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css2?family=Spectral:ital,wght@0,200;0,300;0,400;0,500;0,600;0,700;0,800;1,200;1,300;1,400;1,500;1,600;1,700;1,800&amp;display=swap"> <link defer rel="stylesheet" href="/Personal-Website-New/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/Personal-Website-New/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://shreyansh26.github.io/Personal-Website-New/post/math/"> <script src="/Personal-Website-New/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/Personal-Website-New/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="Personal-Website-New/"> <span class="font-weight-bold">You</span> R. Name </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/Personal-Website-New/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/Personal-Website-New/post/index.html">Posts </a> </li> <li class="nav-item "> <a class="nav-link" href="/Personal-Website-New/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/Personal-Website-New/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/Personal-Website-New/repositories/">repositories </a> </li> <li class="nav-item "> <a class="nav-link" href="/Personal-Website-New/cv/">cv </a> </li> <li class="nav-item "> <a class="nav-link" href="/Personal-Website-New/teaching/">teaching </a> </li> <li class="nav-item "> <a class="nav-link" href="/Personal-Website-New/people/">people </a> </li> <li class="nav-item dropdown "> <a class="nav-link dropdown-toggle" href="#" id="navbarDropdown" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">submenus </a> <div class="dropdown-menu dropdown-menu-right" aria-labelledby="navbarDropdown"> <a class="dropdown-item " href="/Personal-Website-New/publications/">publications</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/Personal-Website-New/projects/">projects</a> <div class="dropdown-divider"></div> <a class="dropdown-item " href="/Personal-Website-New/blog/">blog</a> </div> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <style type="text/css">.post-content{font-family:"Spectral"}.post-header{font-family:"Spectral",serif;font-weight:500;font-style:normal}</style> <div class="post"> <header class="post-header"> <h1 class="post-title">a post with math</h1> <p class="post-meta"> Created in October 20, 2015 </p> <p class="post-tags"> <i class="fa-solid fa-calendar fa-sm"></i> 2015   ·   <i class="fa-solid fa-hashtag fa-sm"></i> formatting   <i class="fa-solid fa-hashtag fa-sm"></i> math   ·   <i class="fa-solid fa-tag fa-sm"></i> sample-posts </p> </header> <article class="post-content"> <div id="markdown-content"> <p>This theme supports rendering beautiful math in inline and display modes using <a href="https://www.mathjax.org/" rel="external nofollow noopener" target="_blank">MathJax 3</a> engine. You just need to surround your math expression with <code class="language-plaintext highlighter-rouge">$$</code>, like <code class="language-plaintext highlighter-rouge">$$ E = mc^2 $$</code>. If you leave it inside a paragraph, it will produce an inline expression, just like \(E = mc^2\).</p> <p>To use display mode, again surround your expression with <code class="language-plaintext highlighter-rouge">$$</code> and place it as a separate paragraph. Here is an example:</p> \[\sum_{k=1}^\infty |\langle x, e_k \rangle|^2 \leq \|x\|^2\] <p>You can also use <code class="language-plaintext highlighter-rouge">\begin{equation}...\end{equation}</code> instead of <code class="language-plaintext highlighter-rouge">$$</code> for display mode math. MathJax will automatically number equations:</p> <p>\begin{equation} \label{eq:cauchy-schwarz} \left( \sum_{k=1}^n a_k b_k \right)^2 \leq \left( \sum_{k=1}^n a_k^2 \right) \left( \sum_{k=1}^n b_k^2 \right) \end{equation}</p> <p>and by adding <code class="language-plaintext highlighter-rouge">\label{...}</code> inside the equation environment, we can now refer to the equation using <code class="language-plaintext highlighter-rouge">\eqref</code>.</p> <p>Note that MathJax 3 is <a href="https://docs.mathjax.org/en/latest/upgrading/whats-new-3.0.html" rel="external nofollow noopener" target="_blank">a major re-write of MathJax</a> that brought a significant improvement to the loading and rendering speed, which is now <a href="http://www.intmath.com/cg5/katex-mathjax-comparison.php" rel="external nofollow noopener" target="_blank">on par with KaTeX</a>.</p> <hr> <ul> <li>Key Questions <ol> <li>Can language models truly develop reasoning skills, or do they simply memorize templates?</li> <li>What is the model’s hidden (mental) reasoning process?</li> <li>Do models solve math questions using skills similar to or different from humans?</li> <li>Do models trained solely on GSM8K-like datasets develop reasoning skills beyond those necessary for solving GSM8K problems?</li> <li>What mental process causes models to make reasoning mistakes?</li> <li>How large or deep must a model be to effectively solve GSM8K-level math questions?</li> </ol> </li> <li> </li> <li>General Idea <ul> <li>To study reasoning and intelligence, a pre-trained model can be fine-tuned on existing math problem datasets like GSM8K.</li> <li>However, there are concerns that GSM8K or similar data may be leaked in the pre-train data for LLMs.</li> <li>Hence when answering mathematical questions, it is hard to tell whether these models are actually performing reasoning (i.e. questions 1-3 above) or has just memorized problem templates during training.</li> <li>Using existing math datasets like GSM8K for pre-training is insufficient due to the small size of these datasets.</li> <li>Also, the idea of using GPT4 to augment similar problems like GSM8K wasn’t chosen because of the potential bias of the augmented data towards a small number of solution templates.</li> <li>Hence the authors created their own pre-training dataset of math problems, with a much larger and diverse set of grade-school math problems to test a GPT2-like language model.</li> </ul> </li> <li> </li> <li>Dataset Generation <ul> <li>This section is super cool but also quiet dense.</li> <li>It is a great source of learning on how to create synthetic datasets. Won’t go into much detail in the notes, the paper is the best source to understand the complexity.</li> <li>A standard grade-school math problem in GSM8K looks like this - <ul> <li> <blockquote> <p>Betty is saving money for a new wallet which costs 100. Betty has only half of the money she needs. Her parents decided to give her 15 for that purpose, and her grandparents twice as much as her parents. How much more money does Betty need to buy the wallet?</p> </blockquote> </li> </ul> </li> <li>This problem has multiple parameters whose values are connected with various equalities, such as “Betty’s current money = 0.5 × cost of the wallet” and “money given by grandparents = 2 × money given by parents.”</li> <li>Motivated by this, the authors build a GSM8K-like math dataset through a synthetic generation pipeline that captures the dependencies of parameters.</li> <li>The main focus was on the “logical reasoning” aspect of the problems which involves understanding the dependency of parameters in the problem statement, such as direct, instance, and implicit dependencies.</li> <li> <strong>Dependency Types</strong>: <ul> <li> <strong>Direct Dependency</strong>: Parameters directly depend on others (e.g., \(A = 5 \times (X + Y)\)).</li> <li> <strong>Instance Dependency</strong>: Parameters depend on instances of categories (e.g., total number of chairs = chairs per classroom × number of classrooms).</li> <li> <strong>Implicit Dependency</strong>: Parameters involve abstract concepts that need to be inferred (e.g., identifying fruits from a list of items).</li> </ul> </li> <li> <strong>Problem Structure</strong>: Problems are generated using a hierarchical categorization of items, where each category can include multiple layers and items. This structure adds complexity by requiring models to learn concepts implicitly.</li> <li> <strong>Dependency Graph</strong>: A directed acyclic graph (DAG) is used to represent dependencies among parameters, including both direct and implicit dependencies. The graph guides the generation of math problems by linking parameters in specific ways.</li> <li> <strong>Problem Generation</strong>: The math problems are articulated by translating the dependency graphs into English sentences. The order of these sentences is randomized to increase the difficulty, and a question is posed to test the model’s understanding.</li> <li><img src="https://remnote-user-data.s3.amazonaws.com/pIotnRPQhSGfbeTmPJ77F4PsDtCuvpDhu2Jp_wOxhLcymDyryAKSgrRJWiEpFZCxc5sClCVqqwk0Nl9GmW4W9kYBNNHSW4-j97w5_3jAWYWpU30sz4tZT7n8F-GdS3Qs.png" alt=""></li> <li>Additional care was taken to reduce the difficulty of the problem statements <ul> <li>Ensuring clarity in expression, to reduce the difficulty arising from common-sense</li> <li>For arithmetic, all integers and arithmetic were mod23</li> </ul> </li> <li>A sample problem (corresponding to the figure above) looks like this -</li> <li> <blockquote> <p>The number of each Riverview High’s Film Studio equals 5 times as much as the sum of each Film Studio’s Backpack and each Dance Studio’s School Daypack. The number of each Film Studio’s School Daypack equals 12 more than the sum of each Film Studio’s Messenger Backpack and each Central High’s Film Studio. The number of each Central High’s Film Studio equals the sum of each Dance Studio’s School Daypack and each Film Studio’s Messenger Backpack. The number of each Riverview High’s Dance Studio equals the sum of each Film Studio’s Backpack, each Film Studio’s Messenger Backpack, each Film Studio’s School Daypack and each Central High’s Backpack. The number of each Dance Studio’s School Daypack equals 17. The number of each Film Studio’s Messenger Backpack equals 13. How many Backpack does Central High have?</p> </blockquote> </li> <li>Solution Construction <ul> <li>The solution generation is done in the Chain of Thought reasoning format.</li> <li>The methpdology is given below - <ul> <li>Let <strong>solution</strong> be a sequence of sentences describing the <strong>necessary</strong> steps towards solving the given problem, where the sentences follow any topological order - known as CoT</li> <li>For each parameter __necessary __ towards answering the final question, it is assigned a random letter among the 52 choices (a..z or A..Z), and a sentence is used to describe its computation.</li> <li>Sample solution corresponding to the above problem -</li> <li> <blockquote> <p>Define Dance Studio’s School Daypack as p; so p = 17. Define Film Studio’s Messenger Backpack as W; so W = 13. Define Central High’s Film Studio as B; so B = p + W = 17 + 13 = 7. Define Film Studio’s School Daypack as g; R = W + B = 13 + 7 = 20; so g = 12 + R = 12 + 20 = 9. Define Film Studio’s Backpack as w; so w = g + W = 9 + 13 = 22. Define Central High’s Backpack as c; so c = B * w = 7 * 22 = 16. __Answer: 16. __</p> </blockquote> </li> </ul> </li> <li>Important points during solution construction - <ul> <li>The solution only contain parameters necessary towards calculating the final query parameter</li> <li>The solution follows the correct logical order: i.e. all the parameters used in the calculation must have appeared and been computed beforehand.</li> <li>Computations are broken into binary ops: $g = 12 + 13 + 7$ is broken into g = 12+R and R = 13+7 in the above solution. The number of semicolons “;” equals the number of operations. This reduces the arithmetic complexity of the solution.</li> </ul> </li> </ul> </li> <li>Difficulty Control <ul> <li>Two parameters are used to control the difficulty of the problem - <ul> <li>$\textrm{ip}$ is the number of instance parameters</li> <li>$\textrm{op}$ is the number of solution operations</li> </ul> </li> <li>The data difficulty is an increasing function over them</li> <li>The authors call the dataset iGSM</li> <li>We use $\textrm{iGSM}^{\textrm{op} \leq op,\textrm{ip} \leq ip}$ to denote the data generated with constraint $\textrm{op} \leq op$ and $\textrm{ip} \leq ip$, and use $\textrm{iGSM}^{\textrm{op}=op,\textrm{ip} \leq ip}$ to denote those restricting to $\textrm{op}=op$.</li> </ul> </li> <li>Train and Test Datasets <ul> <li>$\textrm{iGSM-med}$ uses $\textrm{ip} \leq 20$ <ul> <li>Train data is essentially $\textrm{iGSM}^{\textrm{op} \leq 15,\textrm{ip} \leq 20}$ (referred as $\textrm{iGSM-med}^{\textrm{op} \leq 15}$)</li> <li>Evaluation is done on both $\textrm{iGSM-med}^{\textrm{op} \leq 15}$ and out-of-distribution (OOD) on $\textrm{iGSM-med}^{\textrm{op} \leq op}$ where $op \in {20, 21, 23, 23}$</li> <li>Another set of evaluation is also done on $\textrm{iGSM-med}^{\textrm{op} = op,\textrm{reask}}$. Here $\textrm{reask}$ denotes first generating a problem from $\textrm{iGSM-med}^{\textrm{op} = op}$ and then resampling a query parameter.</li> <li>Due to the topological nature of the data/solution generation process, $\textrm{reask}$ greatly changes the data distribution and the number of operations needed. It provides an excellent OOD sample for evaluation.</li> </ul> </li> <li>$\textrm{iGSM-hard}$ uses $\textrm{ip} \leq 28$ <ul> <li>Train data is essentially $\textrm{iGSM}^{\textrm{op} \leq 21,\textrm{ip} \leq 28}$ (referred as $\textrm{iGSM-hard}^{\textrm{op} \leq 21}$)</li> <li>Evaluation is done on both $\textrm{iGSM-hard}^{\textrm{op} \leq 21}$ and out-of-distribution (OOD) on $\textrm{iGSM-hard}^{\textrm{op} \leq op}$ where $op \in {28, 29, 30, 31, 32}$</li> <li>Another set of evaluation is also done on $\textrm{iGSM-hard}^{\textrm{op} = op,\textrm{reask}}$.</li> </ul> </li> </ul> </li> <li>Key points about the dataset <ul> <li>Ignoring unused parameters, numerics, sentence orderings, English words, a-z and A-Z letter choices, $\textrm{iGSM}^{\textrm{op} = 15}$ still has at least 7 billion solution templates, and $\textrm{iGSM-hard}^{\textrm{op} = 21}$ has at least 90 trillion solution templates.</li> <li>The OOD evaluation is guaranteed to not have data contamination as training is done only on $\textrm{op} \leq 21$ but evaluation is done on $\textrm{op} \geq 28$</li> <li>Training is done on data whose hash value of solution template is $&lt;17$ (mod 23), and but tested with those $\geq 17$. This ensures no template-level overlap between training and testing.</li> </ul> </li> </ul> </li> <li> </li> <li>Model <ul> <li>A GPT2 model but with its positional embedding replaced with rotary embeddings (RoPE)</li> <li>It is still called GPT2 in the paper</li> <li>The authors mostly stick to the 12-layer, 12-head, 768-dim GPT2 (a.k.a. GPT2-small) for experiments but also explore larger models for some experiments</li> <li>The context length is 768 / 1024 for pretraining on $\textrm{iGSM-med}$ / $\textrm{iGSM-hard}$ and 2048 for evaluation.</li> </ul> </li> <li> </li> <li>Key Result - Model’s Behavior process <ul> <li>**TL;DR - ** <ul> <li>The authors demonstrate that the GPT2 model, pretrained on the synthetic dataset, not only achieves 99% accuracy in solving math problems from the same distribution but also out-of-distribution generalizes, such as to those of longer reasoning lengths than any seen during training.</li> <li>Note that the model has never seen any training example of the same length as in test time.</li> <li>This signifies that the model can truly learn some reasoning skill instead of memorizing solution templates.</li> <li><img src="https://remnote-user-data.s3.amazonaws.com/2mIo8FgGbg7AjOyDoJqaJMoTJWDFPhNZX_ATG-h7DLTYAjWKoudL0owHFztptni5QGDk86b-3fotMGniXjYkQGNyCRDznMQq85K0_d2cT0WC3vOcN6L5DVMJpYfI3-kG.png" alt=""></li> <li>Crucially, the model can learn to generate shortest solutions, almost always avoiding unnecessary computations.</li> <li>This suggests that the model formulates a plan before it generates, in order to avoid computing any quantities that are not needed towards solving the underlying math problem.</li> <li><img src="https://remnote-user-data.s3.amazonaws.com/bMjvzJiW6wTicZrS8qMa4hYoNHhg-5BYo05Dezpbg7823i-aSyzKfRXuBFuESfyqSfzmOd9A80uqASssnf_FDMIpXUe4u0BW1VR5ZTxSmouVZSclPRC2P3fFmi6us-W4.png" alt=""></li> </ul> </li> </ul> </li> <li> </li> <li>Key Result - Model’s Mental Process <ul> <li>**TL;DR ** <ul> <li>The authors examine the model’s internal states through probing, introducing six probing tasks to elucidate how the model solves math problems.</li> <li>For instance, they discover that the model (mentally!) preprocesses the full set of necessary parameters before it starts any generation. Likewise, humans also do this preprocess although we write this down on scratch pads.</li> <li>The model also learns unnecessary, yet important skills after pretraining, such as all-pair dependency.</li> <li>Before any question is asked, it already (mentally!) computes with good accuracy which parameters depend on which, even though some are not needed for solving the math problem.</li> <li>Note that computing all-pair dependency is a skill not needed to fit all the solutions in the training data. This is the first evidence that a language model can learn useful skills beyond those necessary to fit its pretraining data.</li> </ul> </li> <li>The authors use linear probing to study the following tasks which align with human problem-solving strategies - <ul> <li>$\textrm{nece(A)}$: If the parameter $A$ is necessary for computing the answer.</li> <li>$\textrm{dep(A, B)}$: if parameter $A$ (recursively) depends on parameter B given the problem statement.</li> <li>$\textrm{known(A)}$: if parameter $A$ has already been computed.</li> <li>$\textrm{value(A)}$: the value of parameter $A$ (a number between 0-22, or 23 if $\textrm{known(A) = false}$).</li> <li>$\textrm{can_next(A)}$: if $A$ can be computed in the next solution sentence (namely, its predecessors have all been calculated). Note that $A$ might not be necessary to answer the question.</li> <li>$\textrm{nece_next(A)}$: if parameter A satisfies both $\textrm{can_next(A)}$ and $\textrm{nece(A)}$.</li> </ul> </li> <li>For a model to generate the shortest solutions, it must identify $\textrm{nece(A)}$ for all $A$’s in its mental process.</li> <li>Whether $\textrm{nece(A)}$ is $\textrm{true}$, directly corresponds to whether there is a solution sentence to compute $A$.</li> <li>Other similar probing tasks and what they imply are shown in the figure below - <ul> <li><img src="https://remnote-user-data.s3.amazonaws.com/0xthPd1KXzoDY39B-FzrXbEf-m3wKuo8dpL2S61U6K3DuXa4GY-t0Bpk_dNDrHUX5zHdPEcYxaNbzr2bgz2EpS6OdQ7Cr5KLWVCb8cii4nfppjd7kENQ77Arhhgw0T6c.png" alt=""></li> </ul> </li> <li>V(ariable)-Probing: A Nearly-Linear Probing Method <ul> <li>As illustrated in the figure above, the authors conduct probing <ul> <li>At the end of the problem description for the $\textrm{dep}$ task</li> <li>At the end of the question description for the $\textrm{nece}$ task</li> <li>For all other tasks, they are probed at the end of every solution sentence</li> </ul> </li> <li>In Linear Probing a trainable linear classifier is introduced over the hidden states and a lightweight finetuning is performed for the task.</li> <li>V-Probing however has certain differences.</li> <li> <strong>Motivation</strong>: V-Probing is introduced to handle more complex properties in math problems that involve one or two conditional variables (A and B) described in plain English.</li> <li> <strong>Probing Setup</strong>: The math problems are truncated to the probing position, and special tokens <code class="language-plaintext highlighter-rouge">[START]</code> and <code class="language-plaintext highlighter-rouge">[END]</code> are placed around the descriptions of A (or A, B). The probing is done from the <code class="language-plaintext highlighter-rouge">[END]</code> token position to check if the property is linearly encoded in the model’s last layer.</li> <li> <strong>Enhancement Over Linear Probing</strong>: Unlike standard linear probing, V-Probing introduces a small, trainable rank-8 linear update to the input embedding layer to account for input changes.</li> <li> <strong>Training Process</strong>: The pretrained language model is frozen, and both the linear classifier and the rank-8 update are fine-tuned to probe for the desired property, making the process more adaptable to complex input structures.</li> <li><img src="https://remnote-user-data.s3.amazonaws.com/HTvVwjA7DehS0gutuKTyQqYUapHb-4NAnpFY-iwG5eX2gsV8p2qU5vDz83NFiOjvlC1Qp_fziYnuQsQ8WOBQOrstWjmR9Y8_VlsR2IeALWRKt2abqpXNvrd0p6DQOoKg.png" alt=""></li> <li>Probing Results <ul> <li>The probing accuracies are high for all the tasks, compared to majority guess and random-model probing - except for the very hard OOD cases (i.e., for large op where the model’s generation accuracies fall down to 80% anyways.</li> <li><img src="https://remnote-user-data.s3.amazonaws.com/vsq4cq0A-isgvZJm3kyKrFc3hoWRlQV7xvlw_TJFXnKU6ahb_H8AfQ7jMj6sb59XvPhcKKPBNA7_2uN0UiEvDjzCZ38AR1zatuTeCKdOFffVtwCWyYnRznvX0N199mYo.png" alt=""></li> <li>**Model solves math problems like humans ** <ul> <li>When generating solutions, the model not only remembers which parameters have been computed and which have not ($\textrm{value, known}$) but <strong>also knows which parameters can be computed next</strong> ($\textrm{can_next, nece_next}$). These abilities <strong>ensure that the model can solve the given math problem step by step</strong>, similar to human problem-solving skill.</li> <li>By the end of the problem description, the model already knows the full list of necessary parameters ($\textrm{nece}$). This indicates that the model has learned to plan ahead, identifying necessary parameters before starting to generate the solution. This aligns with human behavior, except that the model plans mentally while humans typically write this down.</li> </ul> </li> <li> <strong>Model learns beyond human reasoning skills</strong> <ul> <li>The model learns $\textrm{dep(A, B)}$ and $\textrm{can_next(A)}$, even for parameters A not necessary for answering the question, as shown in the figure above.</li> <li>This differs from human problem-solving, where we typically use backward reasoning from the question to identify necessary parameters, often overlooking unnecessary ones.</li> <li>In contrast, language models can pre-compute the all-pair dependency graph $\textrm{dep(A, B)}$ mentally even before a question is asked. This “level-2” reasoning is very different from human behavior or mental processes.</li> <li>This enables the model to sort relationships among the things it hears, a skill that can be useful for future tasks (via instruction fine-tuning).</li> <li>This may be the first evidence of a language model acquiring skills beyond those needed for learning its pretrain data.</li> </ul> </li> </ul> </li> </ul> </li> </ul> </li> <li> </li> <li>Key Results - Explain Model’s Mistakes <ul> <li>The authors tried to answer the following questions - <ul> <li>When does the model answer correctly but include unnecessary parameters?</li> <li>What causes incorrect answers?</li> </ul> </li> <li>The aim is to determine if such erroneous behaviour of the model aligns with errors in the model’s mental process (via probing)</li> <li>Earlier, it was shown that the model rarely produces solutions longer than necessary, so the authors looked at the OOD $\textrm{reask}$ data for evaluation.</li> <li>On this data, pretrained models produce an average of ~0.5 unnecessary parameters per solution even for $\textrm{op} = 32$ (figure 4).</li> <li>The authors examined if these unnecessary parameters $A$ were incorrectly predicted as $\textrm{nece = true}$ in the probing task.</li> <li>The following figure reveals that this is often indeed the case, thus language models produce solutions with unnecessary steps due to errors in their mental planning phase.</li> <li><img src="https://remnote-user-data.s3.amazonaws.com/d48P6Fz-lNG5AdkE5eIAycPY4TQRzomOzJgwocE-UpdTOG9NTZWBUpqafxDW-jj1l7slm0yYFyTVbeL6JRcrigKHLGZgKWdH1ZlzL4-ACpKG6ZSJ91MLbhTBcJZab2sj.png" alt=""></li> <li>In the second part of the figure, the author’s findings show that the model’s errors mainly stem from incorrectly predicting $\textrm{nece_next(A)}$ or $\textrm{can_next(A)}$ as true in its internal states when such $A$’s are not ready for computation.</li> <li>Essentially, <ul> <li>Many reasoning mistakes made by the language model are systematic, stemming from errors in its mental process, not merely random from the generation process.</li> <li>Some of the model’s mistakes can be discovered by probing its inner states even before the model opens its mouth (i.e., before it says the first solution step).</li> </ul> </li> </ul> </li> <li> </li> <li>Key Results - Depth vs. Reasoning Length <ul> <li>The authors find that - <strong>Language model depth is crucial for mathematical reasoning.</strong> </li> <li>They experimented with model of various depths and various hidden sizes.</li> <li><img src="https://remnote-user-data.s3.amazonaws.com/vUhLyU7ZtBFTazwNxrQqG6MHV34je-R5AYGPa9AGFwn_HXgxDG8fP6JnpQolx2qAhOVHgS-nn89THlNtq_n5jt03nFbekm1RRxD7GTNMqGiXkmoorQLBSa85Yq421yE5.png" alt=""></li> <li>From the figure above, it can be seen that a 4-layer transformer, even with 1920 hidden dimensions, underperforms on the math datasets in the paper.</li> <li>Conversely, deeper but smaller models, such as a 20-layer 576-dim, perform very well.</li> <li>There is a clear correlation between the model depth and performance.</li> <li>But how does model depth influence math problem solving skills? <ul> <li>Using the $\textrm{nece}$ probing task, the authors focus on the necessary parameters at distance $t$ from the query parameter, for $t \in {1,2,…,8}$.</li> <li>Though these parameters all have $\textrm{nece = true}$, but the model can be probed to see how correct they are at predicting \(\textrm{nece(A)}\) at different hidden layers.</li> <li><img src="https://remnote-user-data.s3.amazonaws.com/qkMf2om4pfVMz2eTrmHHsPKX1fob729qIKQawzak3kWgCyGJAhnxBqQaen8oPvafIPAkQFCAQit646E1qKfZ7LzTUr20e9xRasYVYXtC-cvp55GQEzhlJS7957lbSVWE.png" alt=""></li> <li>The above figure shows a correlation between the model’s layer hierarchy, reasoning accuracy and mental reasoning depth.</li> <li>Shallower layers excel at predicting nece(A) for parameters $A$ closer to the query, whereas deeper layers are more accurate and can predict $\textrm{nece(A)}$ for parameters further from the query.</li> <li>This suggests that the **model employs layer-by-layer reasoning during the planning phase to recursively identify all parameters the query depends on. **</li> <li>So, for larger $t$, the model may require and benefit from deeper models (assuming all other hyperparameters remain constant).</li> <li>To note - <ul> <li>If the “backward thinking process” is added as CoT to the data, then deep mental thinking is no longer required, reducing the language model’s depth requirement. However, in practice, many such “thinking processes” may not be included in standard math solutions or languages in general.</li> <li>The above claim does not imply that “a $t$-step mental thinking requires a depth-$t$ transformer”. It is plausible for a single transformer layer (containing many sub-layers) to implement $t &gt; 1$ mental thinking steps, though possibly with reduced accuracy as $t$ increases. There is no exact correlation as it depends on the data distribution.</li> </ul> </li> </ul> </li> </ul> </li> </ul> </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 You R. Name. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/Personal-Website-New/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/Personal-Website-New/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/Personal-Website-New/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/Personal-Website-New/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/Personal-Website-New/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/Personal-Website-New/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/Personal-Website-New/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/Personal-Website-New/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/Personal-Website-New/assets/js/search/ninja-keys.min.js?601a2d3465e2a52bec38b600518d5f70"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/Personal-Website-New/"}},{id:"nav-posts",title:"Posts",description:"",section:"Navigation",handler:()=>{window.location.href="/Personal-Website-New/post/index.html"}},{id:"nav-publications",title:"publications",description:"publications by categories in reversed chronological order. generated by jekyll-scholar.",section:"Navigation",handler:()=>{window.location.href="/Personal-Website-New/publications/"}},{id:"nav-projects",title:"projects",description:"A growing collection of your cool projects.",section:"Navigation",handler:()=>{window.location.href="/Personal-Website-New/projects/"}},{id:"nav-repositories",title:"repositories",description:"Edit the `_data/repositories.yml` and change the `github_users` and `github_repos` lists to include your own GitHub profile and repositories.",section:"Navigation",handler:()=>{window.location.href="/Personal-Website-New/repositories/"}},{id:"nav-cv",title:"cv",description:"This is a description of the page. You can modify it in '_pages/cv.md'. You can also change or remove the top pdf download button.",section:"Navigation",handler:()=>{window.location.href="/Personal-Website-New/cv/"}},{id:"nav-teaching",title:"teaching",description:"Materials for courses you taught. Replace this text with your description.",section:"Navigation",handler:()=>{window.location.href="/Personal-Website-New/teaching/"}},{id:"nav-people",title:"people",description:"members of the lab or group",section:"Navigation",handler:()=>{window.location.href="/Personal-Website-New/people/"}},{id:"dropdown-publications",title:"publications",description:"",section:"Dropdown",handler:()=>{window.location.href=""}},{id:"dropdown-projects",title:"projects",description:"",section:"Dropdown",handler:()=>{window.location.href=""}},{id:"dropdown-blog",title:"blog",description:"",section:"Dropdown",handler:()=>{window.location.href="/Personal-Website-New/blog/"}},{id:"post-a-post-with-tabs",title:"a post with tabs",description:"this is what included tabs in a post could look like",section:"Posts",handler:()=>{window.location.href="/Personal-Website-New/post/2024-02-18-dalle3-image-recaptioner/"}},{id:"post-a-post-with-typograms",title:"a post with typograms",description:"this is what included typograms code could look like",section:"Posts",handler:()=>{window.location.href="/Personal-Website-New/post/typograms/"}},{id:"post-a-post-that-can-be-cited",title:"a post that can be cited",description:"this is what a post that can be cited looks like",section:"Posts",handler:()=>{window.location.href="/Personal-Website-New/post/post-citation/"}},{id:"post-a-post-with-pseudo-code",title:"a post with pseudo code",description:"this is what included pseudo code could look like",section:"Posts",handler:()=>{window.location.href="/Personal-Website-New/post/pseudocode/"}},{id:"post-a-post-with-code-diff",title:"a post with code diff",description:"this is how you can display code diffs",section:"Posts",handler:()=>{window.location.href="/Personal-Website-New/post/code-diff/"}},{id:"post-a-post-with-advanced-image-components",title:"a post with advanced image components",description:"this is what advanced image components could look like",section:"Posts",handler:()=>{window.location.href="/Personal-Website-New/post/advanced-images/"}},{id:"post-a-post-with-vega-lite",title:"a post with vega lite",description:"this is what included vega lite code could look like",section:"Posts",handler:()=>{window.location.href="/Personal-Website-New/post/vega-lite/"}},{id:"post-a-post-with-geojson",title:"a post with geojson",description:"this is what included geojson code could look like",section:"Posts",handler:()=>{window.location.href="/Personal-Website-New/post/geojson-map/"}},{id:"post-a-post-with-echarts",title:"a post with echarts",description:"this is what included echarts code could look like",section:"Posts",handler:()=>{window.location.href="/Personal-Website-New/post/echarts/"}},{id:"post-a-post-with-chart-js",title:"a post with chart.js",description:"this is what included chart.js code could look like",section:"Posts",handler:()=>{window.location.href="/Personal-Website-New/post/chartjs/"}},{id:"post-a-post-with-tikzjax",title:"a post with TikZJax",description:"this is what included TikZ code could look like",section:"Posts",handler:()=>{window.location.href="/Personal-Website-New/post/tikzjax/"}},{id:"post-a-post-with-bibliography",title:"a post with bibliography",description:"an example of a blog post with bibliography",section:"Posts",handler:()=>{window.location.href="/Personal-Website-New/post/post-bibliography/"}},{id:"post-a-post-with-jupyter-notebook",title:"a post with jupyter notebook",description:"an example of a blog post with jupyter notebook",section:"Posts",handler:()=>{window.location.href="/Personal-Website-New/post/jupyter-notebook/"}},{id:"post-a-post-with-custom-blockquotes",title:"a post with custom blockquotes",description:"an example of a blog post with custom blockquotes",section:"Posts",handler:()=>{window.location.href="/Personal-Website-New/post/custom-blockquotes/"}},{id:"post-a-post-with-table-of-contents-on-a-sidebar",title:"a post with table of contents on a sidebar",description:"an example of a blog post with table of contents on a sidebar",section:"Posts",handler:()=>{window.location.href="/Personal-Website-New/post/sidebar-table-of-contents/"}},{id:"post-a-post-with-audios",title:"a post with audios",description:"this is what included audios could look like",section:"Posts",handler:()=>{window.location.href="/Personal-Website-New/post/audios/"}},{id:"post-a-post-with-videos",title:"a post with videos",description:"this is what included videos could look like",section:"Posts",handler:()=>{window.location.href="/Personal-Website-New/post/videos/"}},{id:"post-displaying-beautiful-tables-with-bootstrap-tables",title:"displaying beautiful tables with Bootstrap Tables",description:"an example of how to use Bootstrap Tables",section:"Posts",handler:()=>{window.location.href="/Personal-Website-New/post/tables/"}},{id:"post-a-post-with-table-of-contents",title:"a post with table of contents",description:"an example of a blog post with table of contents",section:"Posts",handler:()=>{window.location.href="/Personal-Website-New/post/table-of-contents/"}},{id:"post-a-post-with-giscus-comments",title:"a post with giscus comments",description:"an example of a blog post with giscus comments",section:"Posts",handler:()=>{window.location.href="/Personal-Website-New/post/giscus-comments/"}},{id:"post-a-post-with-redirect",title:"a post with redirect",description:"you can also redirect to assets like pdf",section:"Posts",handler:()=>{window.location.href="/Personal-Website-New/assets/pdf/example_pdf.pdf"}},{id:"post-a-post-with-diagrams",title:"a post with diagrams",description:"an example of a blog post with diagrams",section:"Posts",handler:()=>{window.location.href="/Personal-Website-New/post/diagrams/"}},{id:"post-a-distill-style-blog-post",title:"a distill-style blog post",description:"an example of a distill-style blog post and main elements",section:"Posts",handler:()=>{window.location.href="/Personal-Website-New/post/distill/"}},{id:"post-a-post-with-twitter",title:"a post with twitter",description:"an example of a blog post with twitter",section:"Posts",handler:()=>{window.location.href="/Personal-Website-New/post/twitter/"}},{id:"post-a-post-with-disqus-comments",title:"a post with disqus comments",description:"an example of a blog post with disqus comments",section:"Posts",handler:()=>{window.location.href="/Personal-Website-New/post/disqus-comments/"}},{id:"post-a-post-with-math",title:"a post with math",description:"an example of a blog post with some math",section:"Posts",handler:()=>{window.location.href="/Personal-Website-New/post/math/"}},{id:"post-a-post-with-code",title:"a post with code",description:"an example of a blog post with some code",section:"Posts",handler:()=>{window.location.href="/Personal-Website-New/post/code/"}},{id:"post-a-post-with-images",title:"a post with images",description:"this is what included images could look like",section:"Posts",handler:()=>{window.location.href="/Personal-Website-New/post/images/"}},{id:"post-a-post-with-formatting-and-links",title:"a post with formatting and links",description:"march & april, looking forward to summer",section:"Posts",handler:()=>{window.location.href="/Personal-Website-New/post/formatting-and-links/"}},{id:"news-a-simple-inline-announcement",title:"A simple inline announcement.",description:"",section:"News"},{id:"news-a-long-announcement-with-details",title:"A long announcement with details",description:"",section:"News",handler:()=>{window.location.href="/Personal-Website-New/news/announcement_2/"}},{id:"news-a-simple-inline-announcement-with-markdown-emoji-sparkles-smile",title:'A simple inline announcement with Markdown emoji! <img class="emoji" title=":sparkles:" alt=":sparkles:" src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png" height="20" width="20"> <img class="emoji" title=":smile:" alt=":smile:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f604.png" height="20" width="20">',description:"",section:"News"},{id:"projects-project-1",title:"project 1",description:"with background image",section:"Projects",handler:()=>{window.location.href="/Personal-Website-New/projects/1_project/"}},{id:"projects-project-2",title:"project 2",description:"a project with a background image and giscus comments",section:"Projects",handler:()=>{window.location.href="/Personal-Website-New/projects/2_project/"}},{id:"projects-project-3-with-very-long-name",title:"project 3 with very long name",description:"a project that redirects to another website",section:"Projects",handler:()=>{window.location.href="/Personal-Website-New/projects/3_project/"}},{id:"projects-project-4",title:"project 4",description:"another without an image",section:"Projects",handler:()=>{window.location.href="/Personal-Website-New/projects/4_project/"}},{id:"projects-project-5",title:"project 5",description:"a project with a background image",section:"Projects",handler:()=>{window.location.href="/Personal-Website-New/projects/5_project/"}},{id:"projects-project-6",title:"project 6",description:"a project with no image",section:"Projects",handler:()=>{window.location.href="/Personal-Website-New/projects/6_project/"}},{id:"projects-project-7",title:"project 7",description:"with background image",section:"Projects",handler:()=>{window.location.href="/Personal-Website-New/projects/7_project/"}},{id:"projects-project-8",title:"project 8",description:"an other project with a background image and giscus comments",section:"Projects",handler:()=>{window.location.href="/Personal-Website-New/projects/8_project/"}},{id:"projects-project-9",title:"project 9",description:"another project with an image \ud83c\udf89",section:"Projects",handler:()=>{window.location.href="/Personal-Website-New/projects/9_project/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%79%6F%75@%65%78%61%6D%70%6C%65.%63%6F%6D","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=qc6CJjYAAAAJ","_blank")}},{id:"socials-rss",title:"RSS Feed",section:"Socials",handler:()=>{window.open("Personal-Website-New/feed.xml","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/Personal-Website-New/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>